{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:00:27.432878Z",
     "start_time": "2020-06-16T22:00:23.435250Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from rake_nltk import rake\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll have the user input select the type of destination they'd like recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:00:27.466876Z",
     "start_time": "2020-06-16T22:00:27.438876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select where you'd like to go.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03285df8217649aba16b0af4b385d03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('Coffee Shop', 'Boutique Shop', 'Nightlife'), value='Coffee Shop')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define destination options\n",
    "destination_options = ['Coffee Shop', 'Boutique Shop', 'Nightlife']\n",
    "\n",
    "# Create text widget for output\n",
    "destination_category = widgets.Dropdown(options = destination_options)\n",
    "print(\"Please select where you'd like to go.\")\n",
    "destination_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll request that our user input the Yelp URL of one of their favorite local businesses which falls under the umbrella of the previously selected category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:04:47.608814Z",
     "start_time": "2020-06-16T22:00:27.469881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the Yelp URL of your favorite local business relating to your selected destination category.https://www.yelp.com/biz/greater-goods-coffee-roasters-austin?osq=bee+cave+coffee\n"
     ]
    }
   ],
   "source": [
    "# request url to input Yelp URL\n",
    "user_url = input(\"Please input the Yelp URL of your favorite local business relating to your selected destination category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T19:03:22.148098Z",
     "start_time": "2020-06-11T19:03:22.145093Z"
    }
   },
   "source": [
    "First we'll post a request to have the review data scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:04:47.947954Z",
     "start_time": "2020-06-16T22:04:47.610813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"success\":true,\"job_id\":123325838,\"status\":200,\"message\":\"Added this profile to the queue...\"}\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://app.datashake.com/api/v2/profiles/add\"\n",
    "\n",
    "# url of yelp page to scrape\n",
    "querystring = {\"url\": user_url,\n",
    "               \"blocks\": 100}\n",
    "\n",
    "# provide api key\n",
    "headers = {\n",
    "    'spiderman-token': \"a977b8454ca8cc4324dda1aaf0742d09ff8e72ec\",\n",
    "}\n",
    "\n",
    "# request and print response\n",
    "response = requests.request(\"POST\", request_url, headers=headers, params=querystring)\n",
    "print(response.text)\n",
    "    \n",
    "# obtain job_id and append to list\n",
    "job_id = json.loads(response.text)['job_id']\n",
    "\n",
    "# initialize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will continuously check the status of our scrape request until fulfilled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:57.123712Z",
     "start_time": "2020-06-16T22:26:41.859611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url to check status\n",
    "url = \"https://app.datashake.com/api/v2/profiles/info\"\n",
    "\n",
    "# specify job_id to check status of\n",
    "querystring = {\"job_id\":job_id}\n",
    "\n",
    "# specify token\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    'spiderman-token': \"a977b8454ca8cc4324dda1aaf0742d09ff8e72ec\",\n",
    "    }\n",
    "\n",
    "# use while loop to continue checking status of scrape until 100% complete\n",
    "\n",
    "# initialize percentage complete at zero\n",
    "percentage_complete = 0\n",
    "\n",
    "while percentage_complete < 100:\n",
    "    # check web scraper status\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "    # check percentage complete\n",
    "    percentage_complete = json.loads(response.text)['percentage_complete']\n",
    "    # wait 15 seconds before checking again\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T19:10:26.689659Z",
     "start_time": "2020-06-11T19:10:26.684653Z"
    }
   },
   "source": [
    "Next, we'll have that data retrieved and compile it into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:57.147462Z",
     "start_time": "2020-06-16T22:26:57.131467Z"
    }
   },
   "outputs": [],
   "source": [
    "user_url_reviews_df = pd.DataFrame(columns = ['business_name','source_url','review_ratings', 'review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.144963Z",
     "start_time": "2020-06-16T22:26:57.150456Z"
    }
   },
   "outputs": [],
   "source": [
    "# iterate through first five pages of Yelp review data\n",
    "for page in [1,2,3,4,5]:    \n",
    "    # specify url\n",
    "    url = \"https://app.datashake.com/api/v2/profiles/reviews\"\n",
    "        \n",
    "    # specifiy pages to scrape\n",
    "    querystring = {\"job_id\": job_id,\n",
    "                   \"page\": page}\n",
    "    \n",
    "    # define API token\n",
    "    headers = {\n",
    "        'spiderman-token': \"a977b8454ca8cc4324dda1aaf0742d09ff8e72ec\",\n",
    "        }\n",
    "        \n",
    "    # post request for reviews\n",
    "    response_reviews = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        \n",
    "    # convert response to json object\n",
    "    json_response = json.loads(response_reviews.text)\n",
    "\n",
    "    # grab source url\n",
    "    source_url = json_response['source_url']\n",
    "\n",
    "    # grab business name\n",
    "    business_name = json.loads(json_response['meta_data'])['name']\n",
    "\n",
    "    # grab review rating\n",
    "    review_ratings = []\n",
    "    for review in json_response['reviews']:\n",
    "        review_ratings.append(review['rating_value'])\n",
    "\n",
    "    # grab review text data\n",
    "    review_texts = []\n",
    "    for review in json_response['reviews']:\n",
    "        review_texts.append(review['review_text'])\n",
    "\n",
    "    # append review data to dataframe\n",
    "    user_url_reviews_df = user_url_reviews_df.append(pd.DataFrame({'business_name': business_name,\n",
    "                                                                   'source_url': source_url,\n",
    "                                                                   'review_ratings': [rating for rating in review_ratings],\n",
    "                                                                   'review_text': [text for text in review_texts]}).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.149575Z",
     "start_time": "2020-06-16T22:26:58.146578Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reset index for cleanliness\n",
    "user_url_reviews_df = user_url_reviews_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean New Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Reviews with Less Than Four Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.156539Z",
     "start_time": "2020-06-16T22:26:58.150539Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out all reviews with less than four stars\n",
    "user_url_reviews_df = user_url_reviews_df[user_url_reviews_df['review_ratings'].isin([4.0,5.0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.163541Z",
     "start_time": "2020-06-16T22:26:58.158541Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove \"&#39;\" which is sometimes used in place of apostrophe in contractions\n",
    "user_url_reviews_df['review_text'] = user_url_reviews_df['review_text'].apply(lambda x: str(x).replace(\"&#39;\", \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.169541Z",
     "start_time": "2020-06-16T22:26:58.165538Z"
    }
   },
   "outputs": [],
   "source": [
    "# make all reviews lowercase\n",
    "user_url_reviews_df['review_text'] = user_url_reviews_df['review_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.182541Z",
     "start_time": "2020-06-16T22:26:58.172570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it's\": \"it is\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.195581Z",
     "start_time": "2020-06-16T22:26:58.185541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "user_url_reviews_df['review_text']=user_url_reviews_df['review_text'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.203156Z",
     "start_time": "2020-06-16T22:26:58.197151Z"
    }
   },
   "outputs": [],
   "source": [
    "# define tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_review(review):\n",
    "    # replace <br> breaks with spaces\n",
    "    review = review.replace(\"<br>\", ' ')\n",
    "    # make all characters lowercase\n",
    "    review = review.lower()\n",
    "    # create tokens, use regex to remove all punctuation\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    # remove stopwords\n",
    "    clean_tokens = [token for token in tokens if not token in stop_words]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.211155Z",
     "start_time": "2020-06-16T22:26:58.205153Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply function to dataframes\n",
    "user_url_reviews_df['review_tokens'] =  user_url_reviews_df['review_text'].apply(tokenize_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.216155Z",
     "start_time": "2020-06-16T22:26:58.212151Z"
    }
   },
   "outputs": [],
   "source": [
    "# write function to create bag-of-words from list\n",
    "def bag_of_words(list):\n",
    "    words = ''\n",
    "    for word in list:\n",
    "        words += word + ' '\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.223153Z",
     "start_time": "2020-06-16T22:26:58.218155Z"
    }
   },
   "outputs": [],
   "source": [
    "user_url_reviews_df['bag_of_words'] = user_url_reviews_df['review_tokens'].apply(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate BOW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.233191Z",
     "start_time": "2020-06-16T22:26:58.225154Z"
    }
   },
   "outputs": [],
   "source": [
    "# aggreate all BOWs for each review into single BOW\n",
    "user_url_reviews_grouped = user_url_reviews_df.groupby('business_name').agg({'bag_of_words': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.242152Z",
     "start_time": "2020-06-16T22:26:58.234151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Greater Goods Coffee Roasters</td>\n",
       "      <td>go starbucks support locally owned business us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    bag_of_words\n",
       "business_name                                                                   \n",
       "Greater Goods Coffee Roasters  go starbucks support locally owned business us..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_url_reviews_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:26:58.247155Z",
     "start_time": "2020-06-16T22:26:58.243152Z"
    }
   },
   "outputs": [],
   "source": [
    "# define business name for future reference\n",
    "user_selected_business = user_url_reviews_grouped.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apend Cleaned Dataframe to Appropriate Seattle Businesses BOW Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.434126Z",
     "start_time": "2020-06-16T22:29:59.381155Z"
    }
   },
   "outputs": [],
   "source": [
    "# import Seattle business BOW dataframes\n",
    "seattle_coffee_reviews_grouped = pd.read_csv('seattle_coffee_reviews_grouped.csv') \n",
    "seattle_boutique_reviews_grouped = pd.read_csv('seattle_boutique_reviews_grouped.csv')  \n",
    "seattle_adult_reviews_grouped = pd.read_csv('seattle_adult_reviews_grouped.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.443166Z",
     "start_time": "2020-06-16T22:29:59.435124Z"
    }
   },
   "outputs": [],
   "source": [
    "# set business_name as index\n",
    "seattle_coffee_reviews_grouped.set_index('business_name', inplace=True)\n",
    "seattle_boutique_reviews_grouped.set_index('business_name', inplace=True)\n",
    "seattle_adult_reviews_grouped.set_index('business_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.451124Z",
     "start_time": "2020-06-16T22:29:59.445125Z"
    }
   },
   "outputs": [],
   "source": [
    "# define appropriate dataframe\n",
    "def return_appropriate_dataframe(destination_category):\n",
    "    if destination_category.value == 'Coffee Shop':\n",
    "        df = pd.concat([seattle_coffee_reviews_grouped, user_url_reviews_grouped])\n",
    "    elif destination_category.value == 'Boutique Shop':\n",
    "        df = pd.concat([seattle_boutique_reviews_grouped, user_url_reviews_grouped])\n",
    "    else:\n",
    "        df = pd.concat([seattle_adult_reviews_grouped, user_url_reviews_grouped])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.458124Z",
     "start_time": "2020-06-16T22:29:59.453126Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe with user provided data apended to appropriate dataframe\n",
    "df = return_appropriate_dataframe(destination_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Recommendations and Similarity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.463123Z",
     "start_time": "2020-06-16T22:29:59.459125Z"
    }
   },
   "outputs": [],
   "source": [
    "# create numerical indices for future reference\n",
    "df_indices = pd.Series(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.683166Z",
     "start_time": "2020-06-16T22:29:59.465124Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize \n",
    "df_tfidf = TfidfVectorizer()\n",
    "df_tfidf__matrix = df_tfidf.fit_transform(df['bag_of_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.700123Z",
     "start_time": "2020-06-16T22:29:59.684127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.31754881, 0.46932772, ..., 0.46776336, 0.49412884,\n",
       "        0.44448991],\n",
       "       [0.31754881, 1.        , 0.28869664, ..., 0.30712623, 0.32217561,\n",
       "        0.26021967],\n",
       "       [0.46932772, 0.28869664, 1.        , ..., 0.4224724 , 0.45457909,\n",
       "        0.37430426],\n",
       "       ...,\n",
       "       [0.46776336, 0.30712623, 0.4224724 , ..., 1.        , 0.8031565 ,\n",
       "        0.39201723],\n",
       "       [0.49412884, 0.32217561, 0.45457909, ..., 0.8031565 , 1.        ,\n",
       "        0.40750847],\n",
       "       [0.44448991, 0.26021967, 0.37430426, ..., 0.39201723, 0.40750847,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating the cosine similarity matrix\n",
    "df_cosine_sim = cosine_similarity(df_tfidf__matrix, df_tfidf__matrix)\n",
    "df_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.707164Z",
     "start_time": "2020-06-16T22:29:59.702128Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that takes in movie title as input and returns the top 10 recommended movies\n",
    "def recommendations(business, cosine_sim, indices):\n",
    "    \n",
    "    # initialize empty list of recommended businesses\n",
    "    recommended_businesses = []\n",
    "    \n",
    "    # obtain index of business which matches input\n",
    "    idx = indices[indices == business].index[0]\n",
    "\n",
    "    # creating series with the similarity scores in descending order, convert to list\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # create list of indices for top three businesses\n",
    "    score_series_list = list(score_series.index[1:6])\n",
    "\n",
    "    # add top three recommended businesses to list\n",
    "    for idx in score_series_list:\n",
    "        recommended_businesses.append(indices[idx])\n",
    "        \n",
    "    return recommended_businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T22:29:59.716131Z",
     "start_time": "2020-06-16T22:29:59.710127Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Capitol Coffee Works',\n",
       " 'Street Bean Coffee Roasters',\n",
       " 'Broadcast Coffee Roasters',\n",
       " 'Down Pour Coffee Bar',\n",
       " 'Elm Coffee Roasters']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations(user_selected_business, df_cosine_sim, df_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
